{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_sourcing import DataSourcing\n",
    "with open(\"data/selected_cluster_stocks.txt\", \"r\") as f:\n",
    "    tickers = [line.strip() for line in f]\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2025-06-30'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADM',\n",
       " 'LIN',\n",
       " 'EXR',\n",
       " 'DXCM',\n",
       " 'PAYC',\n",
       " 'AXON',\n",
       " 'PWR',\n",
       " 'CSGP',\n",
       " 'AAPL',\n",
       " 'STLD',\n",
       " 'DECK',\n",
       " 'FTNT',\n",
       " 'ENPH']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established successfully\n",
      "Downloading data for ADM\n",
      "Downloaded 1882 rows for ADM\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for LIN\n",
      "Downloaded 1882 rows for LIN\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for EXR\n",
      "Downloaded 1882 rows for EXR\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for DXCM\n",
      "Downloaded 1882 rows for DXCM\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for PAYC\n",
      "Downloaded 1882 rows for PAYC\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for AXON\n",
      "Downloaded 1882 rows for AXON\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for PWR\n",
      "Downloaded 1882 rows for PWR\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for CSGP\n",
      "Downloaded 1882 rows for CSGP\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for AAPL\n",
      "Downloaded 1882 rows for AAPL\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for STLD\n",
      "Downloaded 1882 rows for STLD\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for DECK\n",
      "Downloaded 1882 rows for DECK\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for FTNT\n",
      "Downloaded 1882 rows for FTNT\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Downloading data for ENPH\n",
      "Downloaded 1882 rows for ENPH\n",
      "Flattened data columns: Index(['date', 'ticker', 'open', 'high', 'low', 'close', 'adj_close',\n",
      "       'volume'],\n",
      "      dtype='object')\n",
      "Database session closed successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_sourcing = DataSourcing(tickers, start_date, end_date)\n",
    "data_sourcing.download_and_store_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for ADM\n",
      "Loading data for LIN\n",
      "Loading data for EXR\n",
      "Loading data for DXCM\n",
      "Loading data for PAYC\n",
      "Loading data for AXON\n",
      "Loading data for PWR\n",
      "Loading data for CSGP\n",
      "Loading data for AAPL\n",
      "Loading data for STLD\n",
      "Loading data for DECK\n",
      "Loading data for FTNT\n",
      "Loading data for ENPH\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.data_preprocessing import DataPreprocessing\n",
    "\n",
    "data_preprocessing = DataPreprocessing()\n",
    "raw_data = data_preprocessing.load_data(tickers)\n",
    "train_data,test_data = data_preprocessing.split_data(raw_data,start_date,end_date,test_start_date='2023-01-01',test_end_date=end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_preprocessing.preprocess_data(train_data)\n",
    "test_data = data_preprocessing.preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data to CSV\n",
    "for ticker, df in train_data.items():\n",
    "    train_directory_path = 'data/processed_data/train'\n",
    "\n",
    "    # Create the directory if it doesn’t exist\n",
    "    os.makedirs(train_directory_path, exist_ok=True)\n",
    "    df.to_csv(f\"{train_directory_path}/{ticker}_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker, df in test_data.items():\n",
    "    test_directory_path = 'data/processed_data/test'\n",
    "\n",
    "    # Create the directory if it doesn’t exist\n",
    "    os.makedirs(test_directory_path, exist_ok=True)\n",
    "    df.to_csv(f\"{test_directory_path}/{ticker}_processed.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "port_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
